Mission : DÃ©ployer des agents IA open-source pour optimiser les opÃ©rations des entreprises puis monÃ©tiser ces solutions. Objectif parallÃ¨le apprentissage Â« en construisant Â» project-based learning

Publics cibles : Ã‰quipes marketing & dÃ©veloppement (niveau dÃ©butant â†’ intermÃ©diaire).

Date de dÃ©marrage : 2025-04-22

Lien ressources externes : Ã  complÃ©ter (Drive / Git)

ğŸ˜ Instructions globales
ğŸ˜ Ton & style
Didactique, pragmatique, structurÃ©.

Langage clair ; jargon limitÃ©.

Ã‰tapes concrÃ¨tes et check-lists orientÃ©es action.

FranÃ§ais par dÃ©faut ; anglais seulement pour noms propres ou citations.

âš ï¸ Contraintes
Solutions exclusivement open-source ou licences permissives.

CompatibilitÃ© API : OpenAI / Anthropic + binaires locaux (llama.cpp, Mistralâ€¦).

DÃ©ploiement : cloud budget modÃ©rÃ© â†’ Docker local (laptop puis VPS).

SÃ©curitÃ© : contrÃ´le humain initial, montÃ©e progressive vers lâ€™autonomie.

Maintien de la cohÃ©rence documentaire : toute dÃ©cision doit Ãªtre reflÃ©tÃ©e dans ce dÃ©pÃ´t.

ğŸ“š Glossaire interne

Terme	DÃ©finition
Agent IA	Processus autonome ou semi-autonome orchestrant appels LLM + outils externes.
LangChain	Framework Python open-source pour chaÃ®nes et agents LLM.
LangServe	Extension FastAPI pour exposer des chaÃ®nes LangChain sous forme dâ€™API REST.
LangGraph	Moteur dâ€™exÃ©cution en graphe dâ€™Ã©tats pour flux LLM complexes.
CrewAI	Orchestrateur multi-agents lÃ©ger, licence Apache-2.0.
Ollama	Runtime Docker facilitant le chargement et le service de modÃ¨les locaux.
Guardrails	Ensemble de rÃ¨gles et validations pour sÃ©curiser les sorties LLM.
Phoenix	Plateforme open-source dâ€™observabilitÃ© et tracing pour applications LLM.

ğŸ“ Changelog initial
v1 â€“ 2025-04-29 : CrÃ©ation du fichier 00_OVERVIEW_INSTRUCTIONS.md.